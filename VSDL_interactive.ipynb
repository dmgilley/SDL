{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sdlabs import strategy,world,material\n",
    "from sdlabs.utility import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, a \"campaign\" or list of campaigns will be created. A campaign consists of an instance of SDL.utility.CampaignInfo. It is a vessel for carrying all information necessary to perform a set of (V)SDL runs. It begines with building an environment. To do so, declare the relevant experiments instances from SDL.world. Check that module for the current options. Then, decide which environment to build. Current option is only VSDLEnvironment. Then, the ML agent will ne to be declared. Decide which to use from SDL.strategy, then feed it the necessary arguments (if deviating from defaults). Finally, you are ready to put it all together into a CampaignInfo instance. You can adjust some campaign arguments, like the number of runs to perform, the sampling procedure, the campaign name, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Campaign 1 - naive BO\n",
    "experiments = {\n",
    "    'BladeCoat': world.BladeCoat(\n",
    "        action_space=['Stability'],\n",
    "        inputs={\n",
    "                'coating_temperature': [0.0,500.0], # C\n",
    "                'speed': [1.0,20.0], # mm/s\n",
    "                'solvent_to_polymer_ratio': [0.0,1.0],\n",
    "                'relative_humidity': [0.0,100.0], # %\n",
    "            },\n",
    "        ),\n",
    "    'Stability': world.Stability(stability_calc=world.g2),\n",
    "}\n",
    "environment = world.VSDLEnvironment(experiments=experiments)\n",
    "agent = strategy.ArchitectureOne(epsilon=0.3)\n",
    "campaign1 = CampaignInfo(\n",
    "    name = 'Architecture One -- Environment 001',\n",
    "    runs = 100,\n",
    "    environment = environment,\n",
    "    agent = agent,\n",
    "    sampling_procedure = [\n",
    "        ('number_of_initial_datapoints', 3),\n",
    "        ('number_of_batches', 10),\n",
    "        ('samples_per_batch', 5)\n",
    "        ],\n",
    ")\n",
    "\n",
    "# Caampaign 2 - RL is better than BO\n",
    "experiments = {\n",
    "    'BladeCoat': world.BladeCoat(\n",
    "        inputs={\n",
    "                'coating_temperature': [0.0,500.0], # C\n",
    "                'speed': [1.0,20.0], # mm/s\n",
    "                'solvent_to_polymer_ratio': [0.0,1.0],\n",
    "                'relative_humidity': [0.0,100.0], # %\n",
    "            },\n",
    "        action_space=['RamanSpectroscopy','UVVisSpectroscopy','Stability']),\n",
    "    'RamanSpectroscopy': world.RamanSpectroscopy(\n",
    "        action_space=['UVVisSpectroscopy','Stability']),\n",
    "    'UVVisSpectroscopy': world.UVVisSpectroscopy(\n",
    "        action_space=['RamanSpectroscopy','Stability']),\n",
    "    'Stability': world.Stability(stability_calc=world.g2),\n",
    "}\n",
    "environment = world.VSDLEnvironment(experiments=experiments)\n",
    "agent = strategy.ArchitectureOne(epsilon=0.3)\n",
    "campaign2 = CampaignInfo(\n",
    "    name = 'Architecture One -- Environment 002',\n",
    "    runs = 100,\n",
    "    environment = environment,\n",
    "    agent = agent,\n",
    "    sampling_procedure = [\n",
    "        ('number_of_initial_datapoints', 3),\n",
    "        ('number_of_batches', 10),\n",
    "        ('samples_per_batch', 5)\n",
    "        ],\n",
    ")\n",
    "\n",
    "# Campaign 3 - RL can select appropriate experiments\n",
    "experiments = {\n",
    "    'BladeCoat': world.BladeCoat(\n",
    "        inputs={\n",
    "                'coating_temperature': [0.0,500.0], # C\n",
    "                'speed': [1.0,20.0], # mm/s\n",
    "                'solvent_to_polymer_ratio': [0.0,1.0],\n",
    "                'relative_humidity': [0.0,100.0], # %\n",
    "            },\n",
    "        action_space=['RamanSpectroscopy','UVVisSpectroscopy','SpectroElectroChemistry','Stability']),\n",
    "    'RamanSpectroscopy': world.RamanSpectroscopy(\n",
    "        action_space=['UVVisSpectroscopy','SpectroElectroChemistry','Stability']),\n",
    "    'UVVisSpectroscopy': world.UVVisSpectroscopy(\n",
    "        action_space=['RamanSpectroscopy','SpectroElectroChemistry','Stability']),\n",
    "    'SpectroElectroChemistry': world.SpectroElectroChemistry(\n",
    "        action_space=['RamanSpectroscopy','UVVisSpectroscopy','Stability']),\n",
    "    'Stability': world.Stability(stability_calc=world.g2),\n",
    "}\n",
    "environment = world.VSDLEnvironment(experiments=experiments)\n",
    "agent = strategy.ArchitectureOne(epsilon=0.3)\n",
    "campaign3 = CampaignInfo(\n",
    "    name = 'Architecture One -- Environment 003',\n",
    "    runs = 100,\n",
    "    environment = environment,\n",
    "    agent = agent,\n",
    "    sampling_procedure = [\n",
    "        ('number_of_initial_datapoints', 3),\n",
    "        ('number_of_batches', 10),\n",
    "        ('samples_per_batch', 5)\n",
    "        ],\n",
    ")\n",
    "\n",
    "# Compile into a campaign list\n",
    "campaign_list = [campaign1,campaign2,campaign3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the campaigns are run. If the number of campaigns and the number of samples to be performed are small, they can be run right in this notebook. If there are many samples, many runs, and/or many campaigns, consider running them using HPC. To do this, dump the campaign list into a binary file using pickle. Then, use the runSDL.py module in this repo to read and run the binary file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run campaign(s) in notebook\n",
    "for campaign in campaign_list:\n",
    "    #campaign.run()\n",
    "    #campaign.run_and_dump_MAE()\n",
    "    \n",
    "    # Dump to a binary input file, to be run on an HPC\n",
    "    dump_campaign_list([campaign], '{}.input.pkl'.format(campaign.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, read the output file (and optionally the MAE file) generated from a campaign. The data will be read in as an instance of SDL.utility.SDLOutputData."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name Architecture Zero -- Environment 000\n",
      "color #\n",
      "calc_stability None\n",
      "runs 2\n",
      "sampling_procedure [('Initial Datapoints per Processing Variable', 3), ('Number of Batches', 2), ('Samples per Batch', 2)]\n",
      "states {1: [[[<sdlabs.material.State object at 0x7f8eb83d9e80>, <sdlabs.material.State object at 0x7f8eb83d9670>], [<sdlabs.material.State object at 0x7f8eb83d9490>, <sdlabs.material.State object at 0x7f8ee8373fd0>], [<sdlabs.material.State object at 0x7f8ee8373ee0>, <sdlabs.material.State object at 0x7f8eb8394820>], [<sdlabs.material.State object at 0x7f8eb84c34c0>, <sdlabs.material.State object at 0x7f8eb84c3970>], [<sdlabs.material.State object at 0x7f8eb84c3bb0>, <sdlabs.material.State object at 0x7f8eb84c37f0>], [<sdlabs.material.State object at 0x7f8eb84c3730>, <sdlabs.material.State object at 0x7f8eb84c3c70>], [<sdlabs.material.State object at 0x7f8eb84c3040>, <sdlabs.material.State object at 0x7f8eb84c3280>], [<sdlabs.material.State object at 0x7f8eb84c3a30>, <sdlabs.material.State object at 0x7f8eb84c3820>], [<sdlabs.material.State object at 0x7f8eb84c3400>, <sdlabs.material.State object at 0x7f8eb84c3490>]], [[<sdlabs.material.State object at 0x7f8eb84c3ac0>, <sdlabs.material.State object at 0x7f8eb84c3d60>], [<sdlabs.material.State object at 0x7f8eb84c3f70>, <sdlabs.material.State object at 0x7f8eb84c3940>]], [[<sdlabs.material.State object at 0x7f8eb84c3a60>, <sdlabs.material.State object at 0x7f8eb83b3d60>], [<sdlabs.material.State object at 0x7f8eb83b36d0>, <sdlabs.material.State object at 0x7f8eb83b3fa0>]]], 2: [[[<sdlabs.material.State object at 0x7f8eb83b3b80>, <sdlabs.material.State object at 0x7f8eb83b3e20>], [<sdlabs.material.State object at 0x7f8eb83b3a30>, <sdlabs.material.State object at 0x7f8eb83b3d30>], [<sdlabs.material.State object at 0x7f8eb83b3bb0>, <sdlabs.material.State object at 0x7f8eb83b3cd0>], [<sdlabs.material.State object at 0x7f8f084b8850>, <sdlabs.material.State object at 0x7f8f084b8b20>], [<sdlabs.material.State object at 0x7f8f084b83a0>, <sdlabs.material.State object at 0x7f8f084b8e50>], [<sdlabs.material.State object at 0x7f8f084b8cd0>, <sdlabs.material.State object at 0x7f8eb84c5580>], [<sdlabs.material.State object at 0x7f8eb84c52e0>, <sdlabs.material.State object at 0x7f8eb84c53a0>], [<sdlabs.material.State object at 0x7f8eb84c57c0>, <sdlabs.material.State object at 0x7f8eb84c5640>], [<sdlabs.material.State object at 0x7f8eb84c56a0>, <sdlabs.material.State object at 0x7f8eb84c5460>]], [[<sdlabs.material.State object at 0x7f8eb84c5490>, <sdlabs.material.State object at 0x7f8eb84c5760>], [<sdlabs.material.State object at 0x7f8eb84c5430>, <sdlabs.material.State object at 0x7f8eb84c5880>]], [[<sdlabs.material.State object at 0x7f8eb84c5850>, <sdlabs.material.State object at 0x7f8eb84c5bb0>], [<sdlabs.material.State object at 0x7f8eb84c59d0>, <sdlabs.material.State object at 0x7f8eb84c5a30>]]]}\n",
      "rewards {1: [[[-10.0, -10.0], [-10.0, -10.0], [-10.0, -10.0], [-10.0, -10.0], [-10.0, -10.0], [-10.0, -10.0], [-10.0, -10.0], [-10.0, -10.0], [-10.0, -10.0]], [[-10.0, -9.928178517009465], [-10.0, -9.973987082228364]], [[-10.0, -9.977699574016437], [-10.0, -9.924558006366338]]], 2: [[[-10.0, -10.0], [-10.0, -10.0], [-10.0, -10.0], [-10.0, -10.0], [-10.0, -10.0], [-10.0, -10.0], [-10.0, -10.0], [-10.0, -10.0], [-10.0, -10.0]], [[-10.0, -9.999990247073718], [-10.0, -10.0]], [[-10.0, -10.0], [-10.0, -9.999990247073718]]]}\n",
      "predicted_stabilities {1: [[[[0.0, 1.0], [39.2, 0.0]], [[0.0, 1.0], [39.2, 0.0]], [[0.0, 1.0], [39.2, 0.0]], [[0.0, 1.0], [70.86666666666667, 0.0]], [[0.0, 1.0], [70.86666666666667, 0.0]], [[0.0, 1.0], [70.86666666666667, 0.0]], [[0.0, 1.0], [102.53333333333336, 0.0]], [[0.0, 1.0], [102.53333333333336, 0.0]], [[0.0, 1.0], [102.53333333333336, 0.0]]], [[[92.93965039627582, 0.066750635200824], [111.96403047811526, 0.0]], [[102.85576662906743, 0.026755785996605143], [102.53333333333336, 0.0]]], [[[68.12245740683336, 0.015191598192194502], [81.27544623454328, 0.0]], [[90.38222262599848, 0.06818615063946785], [85.03806483170766, 0.0]]]], 2: [[[[0.0, 1.0], [39.2, 0.0]], [[0.0, 1.0], [39.2, 0.0]], [[0.0, 1.0], [39.2, 0.0]], [[0.0, 1.0], [70.86666666666667, 0.0]], [[0.0, 1.0], [70.86666666666667, 0.0]], [[0.0, 1.0], [70.86666666666667, 0.0]], [[0.0, 1.0], [102.53333333333336, 0.0]], [[0.0, 1.0], [102.53333333333336, 0.0]], [[0.0, 1.0], [102.53333333333336, 0.0]]], [[[102.53333332308003, 1.0000000413701846e-05], [102.53333333333336, 0.0]], [[0.0, 1.0], [39.20499251179041, 0.0]]], [[[0.0, 1.0], [143.7192359147681, 0.0]], [[102.53333332308003, 1.0000000413701846e-05], [102.53333333333336, 0.0]]]]}\n",
      "stabilities {1: [[39.2, 39.2, 39.2, 70.86666666666667, 70.86666666666667, 70.86666666666667, 102.53333333333336, 102.53333333333336, 102.53333333333336], [111.96403047811526, 102.53333333333336], [81.27544623454328, 85.03806483170766]], 2: [[39.2, 39.2, 39.2, 70.86666666666667, 70.86666666666667, 70.86666666666667, 102.53333333333336, 102.53333333333336, 102.53333333333336], [102.53333333333336, 39.20499251179041], [143.7192359147681, 102.53333333333336]]}\n",
      "GPRs {1: {'BladeCoat': {'kernel': {'length_scale': 1.0, 'length_scale_bounds': [1e-05, 100000.0]}, 'alpha': 1e-10, 'optimizer': 'fmin_l_bfgs_b', 'n_restarts_optimizer': 5, 'normalize_y': False, 'copy_X_train': True, 'n_targets': None, 'random_state': None, 'kernel_': {'length_scale': 54.156961256154894, 'length_scale_bounds': [1e-05, 100000.0]}, '_rng': \"Not jsonable (<class 'numpy.random.mtrand.RandomState'>)\", 'n_features_in_': 2, '_y_train_mean': \"Not jsonable (<class 'numpy.ndarray'>)\", '_y_train_std': \"Not jsonable (<class 'numpy.ndarray'>)\", 'X_train_': \"Not jsonable (<class 'numpy.ndarray'>)\", 'y_train_': \"Not jsonable (<class 'numpy.ndarray'>)\", 'log_marginal_likelihood_value_': -42669.04278328656, 'L_': \"Not jsonable (<class 'numpy.ndarray'>)\", 'alpha_': \"Not jsonable (<class 'numpy.ndarray'>)\"}}, 2: {'BladeCoat': {'kernel': {'length_scale': 1.0, 'length_scale_bounds': [1e-05, 100000.0]}, 'alpha': 1e-10, 'optimizer': 'fmin_l_bfgs_b', 'n_restarts_optimizer': 5, 'normalize_y': False, 'copy_X_train': True, 'n_targets': None, 'random_state': None, 'kernel_': {'length_scale': 59.16002682962264, 'length_scale_bounds': [1e-05, 100000.0]}, '_rng': \"Not jsonable (<class 'numpy.random.mtrand.RandomState'>)\", 'n_features_in_': 2, '_y_train_mean': \"Not jsonable (<class 'numpy.ndarray'>)\", '_y_train_std': \"Not jsonable (<class 'numpy.ndarray'>)\", 'X_train_': \"Not jsonable (<class 'numpy.ndarray'>)\", 'y_train_': \"Not jsonable (<class 'numpy.ndarray'>)\", 'log_marginal_likelihood_value_': -46394.031418946375, 'L_': \"Not jsonable (<class 'numpy.ndarray'>)\", 'alpha_': \"Not jsonable (<class 'numpy.ndarray'>)\"}}}\n",
      "savfs {1: {'BladeCoat': [109, 5.891917654057882e+157], 'Stability': [109, 5.891917654057886e+158]}, 2: {'BladeCoat': [109, -10.994090670293733], 'Stability': [109, -9.940906702937305]}}\n"
     ]
    }
   ],
   "source": [
    "# Read in output from a campaign\n",
    "data = read_output('Architecture Zero -- Environment 000.out.txt')\n",
    "for k,v in data.__dict__.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
